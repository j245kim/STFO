{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 표준 라이브러리\n",
    "from typing import Generator\n",
    "\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# 파이썬 서드파티 라이브러리\n",
    "from langchain_community.callbacks.openai_info import OpenAICallbackHandler\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_core.caches import InMemoryCache\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_core.example_selectors.semantic_similarity import MaxMarginalRelevanceExampleSelector\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain_community.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전역 변수 및 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "folder_path = r'C:\\Users\\RMARKET\\Desktop\\STFO\\STFO'\n",
    "json_path = folder_path + r'\\LLM_Info\\llm_info.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        llm_info = json.load(f)\n",
    "else:\n",
    "    llm_info = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM_Info에 전체 비용, 전체 프롬프트 토큰 갯수, 전체 답변 토큰 갯수, 전체 토큰 갯수를 추가하는 함수\n",
    "def add_info(llm_info: dict[str, float, int],\n",
    "             callback: Generator[OpenAICallbackHandler, None, None]) -> None:\n",
    "    \"\"\"llm_info에 비용, 토큰 갯수들을 추가하는 함수\n",
    "\n",
    "    Args:\n",
    "        llm_info: LLM 비용, 토큰 갯수 등의 정보를 가지고 있는 Dictionary\n",
    "        callback: callback\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    total_cost = callback.total_cost\n",
    "    total_prompt_tokens = callback.prompt_tokens\n",
    "    total_completion_tokens = callback.completion_tokens\n",
    "    total_tokens = callback.total_tokens\n",
    "    llm_info['Total_Cost(USD)'].append(total_cost)\n",
    "    llm_info['Total_Prompt_Tokens'].append(total_prompt_tokens)\n",
    "    llm_info['Total_Completion_Tokens'].append(total_completion_tokens)\n",
    "    llm_info['Total_Tokens'].append(total_tokens)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울에서 관광객이 많이 찾는 3대 명소는 다음과 같습니다:\n",
      "\n",
      "1. **경복궁**: 조선 왕조의 주요 궁궐로, 아름다운 전통 건축과 정원이 인상적입니다. 경복궁 내에는 국립민속박물관과 국립고궁박물관도 있어 한국의 역사와 문화를 깊이 있게 체험할 수 있습니다.\n",
      "\n",
      "2. **N서울타워 (남산타워)**: 서울의 상징적인 랜드마크로, 전망대에서 서울 시내 전경을 한눈에 볼 수 있습니다. 특히 야경이 아름다워 많은 관광객들이 방문합니다. 타워 주변의 남산공원도 산책하기 좋은 장소입니다.\n",
      "\n",
      "3. **명동**: 쇼핑과 먹거리가 풍부한 명동은 외국인 관광객들에게 인기 있는 지역입니다. 다양한 브랜드 매장과 길거리 음식, 카페들이 있어 활기찬 분위기를 즐길 수 있습니다.\n",
      "\n",
      "이 외에도 서울에는 많은 명소가 있으니, 여행 계획에 참고하시기 바랍니다!\n",
      "물론입니다! 서울에서 관광객이 많이 찾는 3대 명소는 다음과 같습니다:\n",
      "\n",
      "1. **경복궁**: \n",
      "   - 조선 왕조의 주요 궁궐로, 한국 전통 건축의 아름다움을 느낄 수 있는 곳입니다. \n",
      "   - 궁궐 내부에는 국립민속박물관과 국립고궁박물관이 있어 한국의 역사와 문화를 배울 수 있는 기회를 제공합니다.\n",
      "   - 매일 정오에 열리는 수문장 교대식도 인기 있는 볼거리입니다.\n",
      "\n",
      "2. **N서울타워 (남산타워)**: \n",
      "   - 서울의 상징적인 랜드마크로, 남산 위에 위치해 있어 서울 전경을 한눈에 볼 수 있는 전망대가 있습니다.\n",
      "   - 특히 야경이 아름다워 많은 관광객들이 저녁에 방문합니다.\n",
      "   - 타워 주변의 남산공원은 산책하기 좋은 장소로, 자연을 즐기며 여유로운 시간을 보낼 수 있습니다.\n",
      "\n",
      "3. **명동**: \n",
      "   - 쇼핑과 먹거리가 풍부한 서울의 대표적인 상업 지역입니다.\n",
      "   - 다양한 브랜드 매장과 화장품 가게, 길거리 음식, 카페들이 있어 활기찬 분위기를 즐길 수 있습니다.\n",
      "   - 특히 외국인 관광객들에게 인기 있는 지역으로, 다양한 한국 음식을 맛볼 수 있는 기회도 많습니다.\n",
      "\n",
      "이 명소들은 서울의 매력을 잘 보여주는 곳들이니, 꼭 방문해 보시길 추천드립니다!\n"
     ]
    }
   ],
   "source": [
    "# 인메모리 캐시를 사용\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\", api_key=openai_api_key, temperature=0.2)\n",
    "messages = [\n",
    "                SystemMessage(content=\"당신은 여행사 직원입니다. 사용자에게 여행 일정을 제공할 수 있습니다.\"),\n",
    "                HumanMessage(content=\"서울에서 관광객이 많이 찾는 3대 명소는 어디예요?\"),\n",
    "            ]\n",
    "\n",
    "with get_openai_callback() as callback:\n",
    "    aiMessage = chat.invoke(messages)\n",
    "    print(aiMessage.content)\n",
    "    messages.append(aiMessage)\n",
    "    add_info(llm_info=llm_info, callback=callback)\n",
    "    \n",
    "    messages.append(HumanMessage(content=\"방금 당신이 알려준 3대 명소들에 대해 다시 알려주세요.\"))\n",
    "    aiMessage = chat.invoke(messages)\n",
    "    add_info(llm_info=llm_info, callback=callback)\n",
    "    print(aiMessage.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM 비용, 프롬프트 토큰 갯수, 답변 토큰 갯수, 전체 토큰 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_path, 'w') as f:\n",
    "    json.dump(llm_info, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 5, updating n_results = 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:Please summarize the weather news.\n",
      " Summary:Today's weather: Sunny skies, mild temperatures, and a gentle breeze. Enjoy the pleasant conditions throughout the day!\n",
      "\n",
      "Input:What is stock market trend?\n",
      " Summary:Investor optimism grows amid easing global trade tensions\n",
      "\n",
      "input: I want to know the economy trends and weather this week.\n",
      "Summary:\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Please summarize the weather news.\\n\",\n",
    "        \"summary\": \"Today's weather: Sunny skies, mild temperatures,\"\n",
    "        \" and a gentle breeze. Enjoy the pleasant conditions throughout the day!\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Please summarize the economy news.\\n\",\n",
    "        \"summary\": \"Global stocks rise on positive economic data;\"\n",
    "        \"inflation concerns persist. Tech sector outperforms; central banks closely monitor.\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Please summarize retail news.\\n\",\n",
    "        \"summary\": \"Major retailer announces record-breaking sales during holiday shopping season\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What is stock market trend?\\n\",\n",
    "        \"summary\": \"Investor optimism grows amid easing global trade tensions\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Typhoon related news.\\n\",\n",
    "        \"summary\": \"IAirports and schools close ahead of approaching typhoon threat\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    template=\"Input:{input} Summary:{summary}\", input_variables=[\"input\", \"summary\"]\n",
    ")\n",
    "example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "    examples,\n",
    "    OpenAIEmbeddings(),\n",
    "    Chroma,\n",
    "    k=2,\n",
    ")\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"input: {input}\\nSummary:\",\n",
    "    prefix=\"\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "output = dynamic_prompt.format(\n",
    "    input=\"I want to know the economy trends and weather this week.\"\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sender_name': 'Terry', 'sender_title': 'CTO', 'sender_contact_email': 'terrycho@exon.example', 'sender_contact_phone': '609-123-1234', 'email_type': 'notification', 'summary': \"Invitation to a Generative AI Product Showcase at the Exxon office in Mountain View on December 1, 2025, discussing Exxon's latest technologies.\", 'date': 'December 1, 2025'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field  # Pydantic V2\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", api_key=openai_api_key)\n",
    "\n",
    "email = \"\"\"\n",
    "## Subject: Invitation to Generative AI Product Showcase\n",
    "\n",
    "Dear [Recipient Name],\n",
    "\n",
    "I am Terry, CTO of Exxon. I am pleased to invite you to a Generative AI Product Showcase at the Exxon office in Mountain View on December 1, 2025.\n",
    "\n",
    "At this event, we will discuss Exxon's latest Generative AI technologies and how they can be used to develop new products and services. Specifically, you will learn about the following topics:\n",
    "\n",
    "* Overview of Generative AI and its key features\n",
    "* Exxon's Generative AI products and services\n",
    "* Case studies of new products and services developed using Generative AI\n",
    "\n",
    "The event will be attended by Terry, CTO of Exxon, and leaders from the Generative AI team. By attending, you will gain up-to-date information on Generative AI technologies and the opportunity to collaborate with Exxon to develop new products and services.\n",
    "\n",
    "**Event Information:**\n",
    "\n",
    "* Date: December 1, 2025\n",
    "* Time: 10:00 AM\n",
    "* Location: Exxon Office (Mountain View)\n",
    "\n",
    "**RSVP:**\n",
    "\n",
    "Please RSVP by email (terrycho@exon.example) or phone (609-123-1234) by November 20, 2025.\n",
    "\n",
    "We look forward to seeing you there.\n",
    "\n",
    "**Thank you.**\n",
    "\n",
    "**Terry**\n",
    "\n",
    "**CTO, Exxon**\n",
    "\n",
    "**Contact:**\n",
    "\n",
    "* Email: terrycho@exon.example\n",
    "* Phone: 609-123-1234\"\"\"\n",
    "\n",
    "\n",
    "class EmailParser(BaseModel):\n",
    "    sender_name: str = Field(description=\"Person who send email\")\n",
    "    sender_title: str = Field(description=\"Job title of the email sender\")\n",
    "    sender_contact_email: str = Field(description=\"Email address of the email sender\")\n",
    "    sender_contact_phone: str = Field(description=\"Phone number of the email sender\")\n",
    "    email_type: str = Field(\n",
    "        description=\"Type of email,it can be personal email, business email, spam, newletter,notificaion\"\n",
    "    )\n",
    "    summary: str = Field(description=\"Short description of the email in 50 words\")\n",
    "    date: str = Field(\n",
    "        description=\"If this email is meeting inviation, this is meeting date and time\"\n",
    "    )\n",
    "\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=EmailParser)\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Parse the email .\\n{format_instructions}\\n{email}\\n\",\n",
    "    input_variables=[\"email\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(email=email)\n",
    "output = model.invoke(prompt)\n",
    "output_text = parser.invoke(output)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"affordability\": \"expensive\",\n",
      "  \"quality\": 3,\n",
      "  \"delivery_time\": 1\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "customer_review = \"\"\"\\\n",
    "I ordered spaghetti delivery, and it tasted good. \\\n",
    "However, the quantity is small compared to the price. \\\n",
    "It took too long for it to be delivered after ordering, so it was cold.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "affordability : if customer feels that the price of the food is high output is expensive. \\\n",
    "if customer feels that the price of the food is affordable, or customer doesn't mention the price,\\\n",
    "output if affordable.\n",
    "\n",
    "quality : If the customer is satisfied with the food quality, output 3, \\\n",
    "if there is no mention or the food quality is average, output 2,\\\n",
    "and if the customer says it is bad, output 1.\n",
    "\n",
    "delivery_time : If the delivery time is fast, mark it as 3, \\\n",
    "if it is average, mark it as 2, and if it is late, mark it as 1.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "affordability\n",
    "quality\n",
    "delivery_time\n",
    "\n",
    "text: {text}\n",
    "\"\"\"\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\", api_key=openai_api_key)\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='My name is Terry', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you Terry', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Where is Seoul?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Seoul is in Korea', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "model = OpenAI(openai_api_key=openai_api_key)\n",
    "# k는 저장할 대화의 수를 의미\n",
    "memory = ConversationBufferWindowMemory(k=2, memory_key='chat_history', return_messages=True)\n",
    "memory.clear()\n",
    "memory.save_context({'input': \"Hello chabot!\"}, {'output': 'Hello. How can I help you?'})\n",
    "memory.save_context({'input': 'My name is Terry'}, {'output': \"Nice to meet you Terry\"})\n",
    "memory.save_context({\"input\": \"Where is Seoul?\"}, {\"output\": \"Seoul is in Korea\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\RMARKET\\Desktop\\STFO\\STFO\\Data\\Hankyung_Data.json', 'r', encoding='utf-8') as f:\n",
    "    data_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [\n",
    "        Document(page_content=news_info['news_content'], metadata={\"source\": news_info['news_url'], \"title\": news_info['news_title'],\n",
    "                                                                   \"date\": news_info['news_first_upload_time'], \"website\": news_info['news_website']})\n",
    "            for news_info in data_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x24a60059950>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs,\n",
    "                                   embedding = embeddings\n",
    "                                  )\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '대한민국'\n",
    "result = vectorstore.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'거액의 가상자산(암호화폐) 보유 논란으로 더불어민주당에서 탈당한 김남국 무소속 의원이 개인 페이스북을 통해 \"22대 총선에 불출마하겠다\"고 22일 밝혔다.\\n아주경제의 보도에 따르면 김 의원은 \"제 문제로 심려를 끼쳐드려 다시 한번 고개 숙여 사과드린다. 제 징계안에 대해 현재 국회 윤리위원회에서 심의 중\"이라며 이같이 언급했다.\\n그는 \"청년정치인에게 국회에서 일할 기회를 주신 안산 단원을 유권자 여러분께 은혜를 갚고 성과로 보답하고자 했으나, 실망을 안겨드려 마음이 무겁다\"며 \"제 간절한 바람이 있다면, 저를 믿고 응원해 준 안산시민을 위해 임기 끝까지 책임을 다하는 것 뿐이다. 남은 임기 동안 하루를 쪼개고 쪼개어 안산시민 여러분과 함께하겠다\"고 말했다.'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "거액의 가상자산(암호화폐) 보유 논란으로 더불어민주당에서 탈당한 김남국 무소속 의원이 개인 페이스북을 통해 \"22대 총선에 불출마하겠다\"고 22일 밝혔다.\n",
      "아주경제의 보도에 따르면 김 의원은 \"제 문제로 심려를 끼쳐드려 다시 한번 고개 숙여 사과드린다. 제 징계안에 대해 현재 국회 윤리위원회에서 심의 중\"이라며 이같이 언급했다.\n",
      "그는 \"청년정치인에게 국회에서 일할 기회를 주신 안산 단원을 유권자 여러분께 은혜를 갚고 성과로 보답하고자 했으나, 실망을 안겨드려 마음이 무겁다\"며 \"제 간절한 바람이 있다면, 저를 믿고 응원해 준 안산시민을 위해 임기 끝까지 책임을 다하는 것 뿐이다. 남은 임기 동안 하루를 쪼개고 쪼개어 안산시민 여러분과 함께하겠다\"고 말했다.\n"
     ]
    }
   ],
   "source": [
    "mmr_docs = vectorstore.max_marginal_relevance_search(query, k=4, fetch_k=10)\n",
    "print(len(mmr_docs))\n",
    "print(mmr_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
