{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14345,
     "status": "ok",
     "timestamp": 1733586568195,
     "user": {
      "displayName": "Seung Hoon Lee",
      "userId": "06197787624635186839"
     },
     "user_tz": -540
    },
    "id": "9HokvFOG2ICx",
    "outputId": "d9c303a8-dc89-45cc-941a-e5b735d02dcd"
   },
   "outputs": [],
   "source": [
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10814,
     "status": "ok",
     "timestamp": 1733586579007,
     "user": {
      "displayName": "Seung Hoon Lee",
      "userId": "06197787624635186839"
     },
     "user_tz": -540
    },
    "id": "oKtWa7v02ICx",
    "outputId": "010a47b4-bff7-4ac7-e294-59fc0f062de2"
   },
   "outputs": [],
   "source": [
    "# !pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6792,
     "status": "ok",
     "timestamp": 1733586585797,
     "user": {
      "displayName": "Seung Hoon Lee",
      "userId": "06197787624635186839"
     },
     "user_tz": -540
    },
    "id": "2Zf1EfhFiiH9",
    "outputId": "6c49166f-fa78-4ce8-be90-231ebe539291"
   },
   "outputs": [],
   "source": [
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcXucBjY20Ci"
   },
   "source": [
    "# 문제점\n",
    "\n",
    "1. 암호화폐 뉴스 사이트들 대부분이 서로 크롤링 하는 경우가 많아서 이미 해당 사건으로부터 몇 십분에서 몇 시간, 며칠이 지난 후에 뉴스가 올라오는 경우가 되게 많음\n",
    "\n",
    "예: A사이트는 B사이트를 크롤링해서 뉴스 게재 -> B사이트는 C사이트를 크롤링해서 뉴스 게재 -> C사이트는 A사이트를 크롤링해서 게재\n",
    "\n",
    "2. 원인 불명의 문제로 인해 크롤링할 때 일부 뉴스 데이터들이 누락"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4H1DYrC82ICy"
   },
   "source": [
    "# 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1733665110553,
     "user": {
      "displayName": "Seung Hoon Lee",
      "userId": "06197787624635186839"
     },
     "user_tz": -540
    },
    "id": "auvaotrw2ICz"
   },
   "outputs": [],
   "source": [
    "# 파이썬 표준 라이브러리\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from concurrent import futures\n",
    "\n",
    "# 파이썬 서드파티 라이브러리\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxDIDmyG2IDA"
   },
   "source": [
    "# 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_html(\n",
    "                url: str, headers: dict[str, str], allow_redirects: bool, timeout: int,\n",
    "                 max_retry: int\n",
    "                 ) -> str | None:\n",
    "    \"\"\"requests로 HTML 문서 정보를 불러오는 함수\n",
    "\n",
    "    Args:\n",
    "        url: URL\n",
    "        headers: 식별 정보\n",
    "        allow_redirects: 리다이렉트 허용 여부\n",
    "        timeout: 응답 대기 허용 시간\n",
    "        max_retry: HTML 문서 정보 불러오기에 실패했을 때 재시도할 최대 횟수\n",
    "    \n",
    "    Return:\n",
    "        텍스트화한 HTML 문서 정보, str\n",
    "\n",
    "        or \n",
    "    \n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    html = None\n",
    "\n",
    "    for _ in range(max_retry):\n",
    "        # requests로 HTML GET\n",
    "        response = requests.get(url, headers=headers, allow_redirects=allow_redirects, timeout=timeout)\n",
    "        # HTML 문서 정보를 불러오는 것에 성공하면 for문 중단\n",
    "        if response.ok and response.status_code == requests.codes.ok:\n",
    "            html = response.text\n",
    "            break\n",
    "\n",
    "        time.sleep(random.uniform(0.5, 1.25))\n",
    "    \n",
    "    # 응답 요청이 실패했으면 메세지 출력\n",
    "    if html is None:\n",
    "        print()\n",
    "        print(response.reason)\n",
    "        print(f'HTML 문서 정보 가져오기를 실패한 URL : {url}')\n",
    "    \n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1733669946448,
     "user": {
      "displayName": "Seung Hoon Lee",
      "userId": "06197787624635186839"
     },
     "user_tz": -540
    },
    "id": "jdcV0NWCW0rV"
   },
   "outputs": [],
   "source": [
    "def investing(\n",
    "            news_url: str, headers: dict[str, str], allow_redirects: bool, timeout: int, max_retry: int,\n",
    "              p0: re.Pattern, p1: re.Pattern, p2: re.Pattern, p3: re.Pattern, p4: re.Pattern, p5: re.Pattern\n",
    "              ) -> dict[str, str, None] | None:\n",
    "    \"\"\"뉴스 URL을 바탕으로 크롤링을 하는 함수\n",
    "\n",
    "    Args:\n",
    "        news_url_tag: 뉴스 URL\n",
    "        headers: 식별 정보\n",
    "        allow_redirects: 리다이렉트 허용 여부\n",
    "        timeout: 응답 대기 허용 시간\n",
    "        max_retry: HTML 문서 정보 불러오기에 실패했을 때 재시도할 최대 횟수\n",
    "        p0: \"입력: \\r\\n 2024- 12- 07- 오후 08:45\"와 같은 텍스트에서 ' \\r\\n '를 기준으로 분리하는 패턴\n",
    "        p1: \\n가 1개 이상 연속되는 패턴\n",
    "        p2: 디셉터에서 읽기 / Provided COINNESS / 이승훈 기자 123@gmail.com 등의 불필요한 텍스트 패턴\n",
    "        p3: \"습니다.그 결과,\"와 같은 텍스트에서 마침표 다음 띄워쓰기를 보정\n",
    "        p4: \"필요하다.━AI로\"와 같은 텍스트에서 마침표 다음 줄바꿈을 보정\n",
    "        p5: 줄바꿈이 3번 이상 연속하는 패턴\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "            \"news_title\": 뉴스 제목, str\n",
    "            \"news_first_upload_time\": 뉴스 최초 업로드 시각, str | None\n",
    "            \"newsfinal_upload_time\": 뉴스 최종 수정 시각, str | None\n",
    "            \"author\": 뉴스 작성자, str | None\n",
    "            \"news_content\": 뉴스 본문, str\n",
    "            \"news_url\": 뉴스 URL, str\n",
    "            \"news_website\": 뉴스 웹사이트, str\n",
    "            \"note\": 비고, str | None\n",
    "        }\n",
    "\n",
    "        or\n",
    "\n",
    "        None\n",
    "    \"\"\"\n",
    "    info = {} # 뉴스 데이터 정보 Dictionary\n",
    "\n",
    "    # requests로 HTML GET\n",
    "    html = request_html(url=news_url, headers=headers, allow_redirects=allow_redirects, timeout=timeout, max_retry=max_retry)\n",
    "    # HTML 문서 정보를 불러오는 것에 실패하면 None 반환\n",
    "    if html is None:\n",
    "        return None\n",
    "    # BeautifulSoup로 parser\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 1. 뉴스 데이터의 제목\n",
    "    title = soup.find('h1', id='articleTitle')\n",
    "    title = title.text.strip(' \\t\\n\\r\\f\\v')\n",
    "\n",
    "    # 2. 뉴스 데이터의 최초 업로드 시각과 최종 수정 시각\n",
    "    div = soup.find_all('div', {'class': 'flex flex-row items-center'})\n",
    "    span = div[1].find('span')\n",
    "    span = span.text.strip(' \\t\\n\\r\\f\\v')\n",
    "\n",
    "    first_upload_time_list = p0.split(string=span)[1].split()\n",
    "    y_m_d = '-'.join(times[:-1] for times in first_upload_time_list[:3])\n",
    "    if first_upload_time_list[3] == '오전':\n",
    "        ap = 'AM'\n",
    "    else:\n",
    "        ap = 'PM'\n",
    "\n",
    "    first_upload_time = y_m_d + ' ' + ap + ' ' + first_upload_time_list[4]\n",
    "    last_upload_time = None\n",
    "\n",
    "\n",
    "    # 3. 뉴스 데이터의 기사 작성자\n",
    "    author = None\n",
    "\n",
    "    # 4. 뉴스 데이터의 본문\n",
    "    article = soup.find('div', id='article')\n",
    "    while (td_tag := article.find(\"td\")) is not None:\n",
    "        td_tag.decompose()\n",
    "    \n",
    "    # li 태그 밑의 하위 태그들을 텍스트만 남기고 모두 제거\n",
    "    for tag in article.find_all('li'):\n",
    "        text_content = ''.join(tag.stripped_strings)\n",
    "        tag.clear()  # 하위 태그 모두 제거\n",
    "        tag.string = f'\\n\\n-> {text_content}\\n\\n'  # 텍스트만 남김\n",
    "    \n",
    "    # em 태그의 시작에 \\n\\n을 추가\n",
    "    if (em_tag := article.find('em')) is not None:\n",
    "        em_tag.string = f'\\n\\n{em_tag.text}'\n",
    "\n",
    "    all_text = article.text.strip(' \\t\\n\\r\\f\\v')\n",
    "    news_content = p1.split(string=all_text)\n",
    "    # 뉴스 데이터 본문의 데이터 전처리1\n",
    "    # 디셉터에서 읽기 / Provided COINNESS / 이승훈 기자 123@gmail.com 등의 불필요한 텍스트 제거\n",
    "    while news_content:\n",
    "        if  p2.search(string=news_content[-1]) is None:\n",
    "            break\n",
    "        del news_content[-1]\n",
    "        \n",
    "    # 뉴스 데이터 본문의 데이터 전처리2\n",
    "    # - 하나의 텍스트로 결합하되, 사이에 줄바꿈 2개 추가\n",
    "    # - 띄워쓰기 보정\n",
    "    # - 줄바꿈 보정1, 2\n",
    "    # - 맨 앞/뒤의 화이트스페이스(whitespace) 문자 제거\n",
    "    content = '\\n\\n'.join(news_content)\n",
    "    content = p3.sub(repl=r'\\g<1>. \\g<2>', string=content)\n",
    "    content = p4.sub(repl=r'.\\n\\n━', string=content)\n",
    "    content = p5.sub(repl=r'\\n\\n', string=content)\n",
    "    content = content.strip(' \\t\\n\\r\\f\\v')\n",
    "\n",
    "    # 5. 뉴스 웹사이트 이름\n",
    "    website = 'Investing'\n",
    "\n",
    "    # 6. 뉴스 카테고리\n",
    "    category = None\n",
    "    \n",
    "    # 7. 비고\n",
    "    note = None\n",
    "\n",
    "    info['news_title'] = title\n",
    "    info['news_first_upload_time'] = first_upload_time\n",
    "    info['news_last_upload_time'] = last_upload_time\n",
    "    info['author'] = author\n",
    "    info['news_content'] = content\n",
    "    info['news_url'] = news_url\n",
    "    info['news_website'] = website\n",
    "    info['news_category'] = category\n",
    "    info['note'] = note\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1733669946843,
     "user": {
      "displayName": "Seung Hoon Lee",
      "userId": "06197787624635186839"
     },
     "user_tz": -540
    },
    "id": "3MFKvcUcUq9_"
   },
   "outputs": [],
   "source": [
    "def hankyung(\n",
    "            news_url: str, headers: dict[str, str], allow_redirects: bool, timeout: int, max_retry: int,\n",
    "              p0: re.Pattern\n",
    "              ) -> dict[str, str, None] | None:\n",
    "    \"\"\"뉴스 URL을 바탕으로 크롤링을 하는 함수\n",
    "\n",
    "    Args:\n",
    "        news_url_tag: 뉴스 URL\n",
    "        headers: 식별 정보\n",
    "        allow_redirects: 리다이렉트 허용 여부\n",
    "        timeout: 응답 대기 허용 시간\n",
    "        max_retry: HTML 문서 정보 불러오기에 실패했을 때 재시도할 최대 횟수\n",
    "        p0: 인도 벵갈루루=양한나 블루밍비트 기자 sheep@bloomingbit.io / (사진=연합뉴스)와같은 텍스트 패턴\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "            \"news_title\": 뉴스 제목, str\n",
    "            \"news_first_upload_time\": 뉴스 최초 업로드 시각, str | None\n",
    "            \"newsfinal_upload_time\": 뉴스 최종 수정 시각, str | None\n",
    "            \"author\": 뉴스 작성자, str | None\n",
    "            \"news_content\": 뉴스 본문, str\n",
    "            \"news_url\": 뉴스 URL, str\n",
    "            \"news_website\": 뉴스 웹사이트, str\n",
    "            \"note\": 비고, str | None\n",
    "        }\n",
    "\n",
    "        or\n",
    "\n",
    "        None\n",
    "    \"\"\"\n",
    "    info = {} # 뉴스 데이터 정보 Dictionary\n",
    "\n",
    "    # requests로 HTML GET\n",
    "    html = request_html(url=news_url, headers=headers, allow_redirects=allow_redirects, timeout=timeout, max_retry=max_retry)\n",
    "    # HTML 문서 정보를 불러오는 것에 실패하면 None 반환\n",
    "    if html is None:\n",
    "        return None\n",
    "    # BeautifulSoup로 parser\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 1. 뉴스 데이터의 제목\n",
    "    title = soup.find('h1', {\"class\": \"headline\"})\n",
    "    title = title.text.strip(' \\t\\n\\r\\f\\v')\n",
    "\n",
    "    # 2. 뉴스 데이터의 최초 업로드 시각과 최종 수정 시각\n",
    "    upload_times = soup.find_all('span', {\"class\": \"txt-date\"})\n",
    "\n",
    "    first_upload_time = upload_times[0].text\n",
    "    first_upload_time = datetime.strptime(first_upload_time, '%Y.%m.%d %H:%M')\n",
    "    first_upload_time = datetime.strftime(first_upload_time, '%Y-%m-%d %p %I:%M')\n",
    "    last_upload_time = upload_times[1].text\n",
    "    last_upload_time = datetime.strptime(last_upload_time, '%Y.%m.%d %H:%M')\n",
    "    last_upload_time = datetime.strftime(last_upload_time, '%Y-%m-%d %p %I:%M')\n",
    "\n",
    "    # 3. 뉴스 데이터의 기사 작성자\n",
    "    author_list = soup.find_all('div', {\"class\": \"author link subs_author_list\"})\n",
    "    author_list = map(lambda x: x.find(\"a\").text, author_list)\n",
    "    author = ', '.join(author_list)\n",
    "\n",
    "    # 4. 뉴스 데이터의 본문\n",
    "    articletxt = soup.find(\"div\", id=\"articletxt\")\n",
    "    while (strong_tag := articletxt.find(\"strong\")) is not None:\n",
    "        strong_tag.decompose()\n",
    "    while (figcaption_tag := articletxt.find(\"figcaption\")) is not None:\n",
    "        figcaption_tag.decompose()\n",
    "    text_list = articletxt.get_text(separator=\"\\n\", strip=True).split('\\n')\n",
    "    while text_list:\n",
    "        if p0.search(string=text_list[-1]) is None:\n",
    "            break\n",
    "        del text_list[-1]\n",
    "        \n",
    "    content = '\\n\\n'.join(text_list).strip(' \\t\\n\\r\\f\\v')\n",
    "\n",
    "    # 5. 뉴스 웹사이트 이름\n",
    "    website = 'Hankyung'\n",
    "\n",
    "    # 6. 뉴스 카테고리\n",
    "    category = None\n",
    "    \n",
    "    # 7. 비고\n",
    "    note = None\n",
    "\n",
    "    info['news_title'] = title\n",
    "    info['news_first_upload_time'] = first_upload_time\n",
    "    info['news_last_upload_time'] = last_upload_time\n",
    "    info['author'] = author\n",
    "    info['news_content'] = content\n",
    "    info['news_url'] = news_url\n",
    "    info['news_website'] = website\n",
    "    info['news_category'] = category\n",
    "    info['note'] = note\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1733669946843,
     "user": {
      "displayName": "Seung Hoon Lee",
      "userId": "06197787624635186839"
     },
     "user_tz": -540
    },
    "id": "ham3rmXQ2IDA"
   },
   "outputs": [],
   "source": [
    "def crawling(website: str, news_websites_dict: dict[str, str]):\n",
    "    \"\"\"Crawling을 하는 함수\n",
    "\n",
    "    Args:\n",
    "        website: 웹사이트 이름, str\n",
    "        news_websites_dict: 웹사이트 Dictionary, dict[str, str]\n",
    "\n",
    "    Returns:\n",
    "        pass\n",
    "    \"\"\"\n",
    "\n",
    "    assert website in news_websites_dict, f'{website}은 대상 웹사이트가 아닙니다.'\n",
    "\n",
    "    match website:\n",
    "        case 'Investing':\n",
    "            pass\n",
    "\n",
    "        case 'Hankyung':\n",
    "            pass\n",
    "\n",
    "        case 'Bloomingbit':\n",
    "            pass\n",
    "\n",
    "        case 'Coinreaders':\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전역 변수 및 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# cpu 갯수\n",
    "workers = os.cpu_count()\n",
    "print(workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_websites_dict = {\n",
    "                        'Investing': 'https://kr.investing.com/news/cryptocurrency-news',\n",
    "                        'Hankyung': 'https://www.hankyung.com/koreamarket/news/crypto',\n",
    "                        'Bloomingbit': 'https://bloomingbit.io/feed',\n",
    "                        'Coinreaders': 'https://www.coinreaders.com/'\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-Agent 변경을 위한 옵션 설정\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "headers = {'User-Agent': user_agent}\n",
    "\n",
    "# requests 파라미터\n",
    "allow_redirects = True # 리다이렉트 허용 여부\n",
    "timeout = 90 # 응답 대기 허용 시간\n",
    "max_retry = 10 # HTML 문서 요청 최대 재시도 횟수\n",
    "\n",
    "# 경로\n",
    "investing_path = r'C:\\Users\\User\\Desktop\\STFO_Project\\datas\\news_data\\Investing_Data.json'\n",
    "hankyung_path = r'C:\\Users\\User\\Desktop\\STFO_Project\\datas\\news_data\\Hankyung_Data.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bycij_yb2IDB"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwxuzzaF2IDC"
   },
   "source": [
    "## https://kr.investing.com/news/cryptocurrency-news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUegd-BSCjwG"
   },
   "source": [
    "### 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1263346,
     "status": "ok",
     "timestamp": 1733671553966,
     "user": {
      "displayName": "Seung Hoon Lee",
      "userId": "06197787624635186839"
     },
     "user_tz": -540
    },
    "id": "Ltv-G6ZTU_0p",
    "outputId": "1810bf2b-abe8-48f8-843d-dbf40bc19dc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [03:07<00:00,  6.26s/it]\n"
     ]
    }
   ],
   "source": [
    "web_page = 'https://kr.investing.com/news/cryptocurrency-news'\n",
    "start = 1\n",
    "get_page_cnt = 30\n",
    "end = start + get_page_cnt\n",
    "p0 = re.compile(pattern=r'\\s+\\r\\n\\s+')\n",
    "p1 = re.compile(pattern=r'\\n+')\n",
    "p2 = re.compile(pattern=r'(읽기|provided|[a-z0-9]@[a-z0-9]|무단전재 및 재배포|이 글의 독자는 인베스팅프로 결제 시 쿠폰 코드|인베스팅닷컴 유저를 위한|지금 인베스팅프로)', flags=re.IGNORECASE)\n",
    "p3 = re.compile(pattern=r'([가-힣])\\.(\\w)')\n",
    "p4 = re.compile(pattern=r'\\.━')\n",
    "p5 = re.compile(pattern=r'\\n{3,}')\n",
    "# 일부 파라미터들을 고정한 investing 함수 생성\n",
    "fixed_investing = partial(investing,\n",
    "                            headers=headers, allow_redirects=allow_redirects, timeout=timeout, max_retry=max_retry,\n",
    "                            p0=p0, p1=p1, p2=p2, p3=p3, p4=p4, p5=p5)\n",
    "investing_results = []\n",
    "\n",
    "for i in tqdm(range(start, end), mininterval=1, miniters=1):\n",
    "    try:\n",
    "        html = request_html(url=web_page, headers=headers, allow_redirects=allow_redirects, timeout=timeout, max_retry=max_retry)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        url_tag_list = soup.find_all('article', {\"data-test\": \"article-item\"})\n",
    "        url_list = [url[\"href\"] for url_tag in url_tag_list if ((url := url_tag.find('a')) is not None)]\n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print(f'{i}번 페이지의 HTML 문서 정보를 불러오는데 실패했습니다.')\n",
    "        print(traceback.format_exc())\n",
    "        web_page = f'https://kr.investing.com/news/cryptocurrency-news/{i + 1}'\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with futures.ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "            data = executor.map(fixed_investing, url_list)\n",
    "\n",
    "        for idx, d in enumerate(data, start=1):\n",
    "            if d is not None:\n",
    "                investing_results.append(d)\n",
    "            else:\n",
    "                print()\n",
    "                print(f'-{i}번 페이지-')\n",
    "                print(f'{i}번 페이지의 {idx}번째 데이터를 가져오는 것에 실패했습니다.')\n",
    "                print(f'실패한 뉴스 데이터의 URL : {url_list[idx - 1]}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print(f'-{i}번 페이지-')\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "    time.sleep(random.uniform(0.5, 1.25))\n",
    "    web_page = f'https://kr.investing.com/news/cryptocurrency-news/{i + 1}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVIrAc7ZCmQd"
   },
   "source": [
    "### JSON으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1733671674719,
     "user": {
      "displayName": "Seung Hoon Lee",
      "userId": "06197787624635186839"
     },
     "user_tz": -540
    },
    "id": "j1Hs6CWGcRYa"
   },
   "outputs": [],
   "source": [
    "with open(investing_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(investing_results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxW9SY3VjBWk"
   },
   "source": [
    "## https://www.hankyung.com/koreamarket/news/crypto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BX74tfLYnZ3S"
   },
   "source": [
    "### 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11688,
     "status": "ok",
     "timestamp": 1733670082440,
     "user": {
      "displayName": "Seung Hoon Lee",
      "userId": "06197787624635186839"
     },
     "user_tz": -540
    },
    "id": "nvQK7B2Fi06x",
    "outputId": "ae2f0f40-ca1b-4b38-ada7-8d69b3c577b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [11:42<00:00,  3.51s/it]\n"
     ]
    }
   ],
   "source": [
    "start = 1\n",
    "get_page_cnt = 200\n",
    "end = start + get_page_cnt\n",
    "p0 = re.compile(pattern=r'([a-z0-9]@[a-z0-9]|사진=|\\b기자\\b|영상촬영\\s*:|한국경제TV [가-힣]{2,4}입니다)', flags=re.IGNORECASE)\n",
    "\n",
    "# 일부 파라미터들을 고정한 hankyung 함수 생성\n",
    "fixed_hankyung = partial(hankyung,\n",
    "                            headers=headers, allow_redirects=allow_redirects, timeout=timeout, max_retry=max_retry,\n",
    "                            p0=p0)\n",
    "hankyung_results = []\n",
    "\n",
    "for i in tqdm(range(start, end)):\n",
    "    web_page = f'https://www.hankyung.com/koreamarket/news/crypto?page={i}'\n",
    "    try:\n",
    "        html = request_html(url=web_page, headers=headers, allow_redirects=allow_redirects, timeout=timeout, max_retry=max_retry)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        url_tag_list = soup.find_all('h2', {\"class\": \"news-tit\"})\n",
    "        url_list = [url[\"href\"] for url_tag in url_tag_list if ((url := url_tag.find('a')) is not None)]\n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print(f'{i}번 페이지의 HTML 문서 정보를 불러오는데 실패했습니다.')\n",
    "        print(traceback.format_exc())\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with futures.ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "            data = executor.map(fixed_hankyung, url_list)\n",
    "\n",
    "        for idx, d in enumerate(data, start=1):\n",
    "            if d is not None:\n",
    "                hankyung_results.append(d)\n",
    "            else:\n",
    "                print()\n",
    "                print(f'-{i}번 페이지-')\n",
    "                print(f'{i}번 페이지의 {idx}번째 데이터를 가져오는 것에 실패했습니다.')\n",
    "                print(f'실패한 뉴스 데이터의 URL : {url_list[idx - 1]}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print(f'-{i}번 페이지-')\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "    time.sleep(random.uniform(0.5, 1.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZb1FuoSZ0RJ"
   },
   "source": [
    "### JSON으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1733667830226,
     "user": {
      "displayName": "Seung Hoon Lee",
      "userId": "06197787624635186839"
     },
     "user_tz": -540
    },
    "id": "tF3M18pXZ0RK"
   },
   "outputs": [],
   "source": [
    "with open(hankyung_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(hankyung_results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마이크로스트래티지(MicroStrategy Inc.) (NASDAQ:MSTR)가 다음과 같이 공시했습니다:\n",
      "\n",
      "항목 8.01.\n",
      "\n",
      "기타 사건.\n",
      "\n",
      "ATM 업데이트\n",
      "\n",
      "이전에 공시된 바와 같이, 2024년 10월 30일 마이크로스트래티지(\"마이크로스트래티지\" 또는 \"회사\")는 TD Securities (USA) LLC, Barclays Capital Inc., The Benchmark Company, LLC, BTIG, LLC, Canaccord Genuity LLC, Cantor Fitzgerald & Co., Maxim Group LLC, Mizuho Securities USA LLC, SG Americas Securities, LLC와 판매 대리인(\"판매 대리인\")으로서 판매 계약(\"판매 계약\")을 체결했습니다. 이에 따라 회사는 판매 대리인을 통해 수시로 총 발행 가격이 $21 billion에 달하는 액면가 $0.001의 A종 보통주(\"주식\")를 발행하고 판매할 수 있습니다.\n",
      "\n",
      "2024년 12월 9일, 회사는 2024년 12월 2일부터 2024년 12월 8일 사이에 판매 계약에 따라 총 5,418,449주를 판매하여 회사에 약 $2.13 billion의 순수익(판매 수수료 제외)을 안겼다고 발표했습니다. 2024년 12월 8일 기준으로 판매 계약에 따라 약 $9.19 billion 상당의 주식이 발행 및 판매 가능한 상태로 남아있습니다.\n",
      "\n",
      "비트코인 보유 현황 업데이트\n",
      "\n",
      "2024년 12월 9일, 회사는 2024년 12월 2일부터 2024년 12월 8일 사이에 약 21,550 비트코인을 약 $2.1 billion의 현금으로 매입했다고 발표했습니다. 비트코인당 평균 구매 가격은 수수료와 비용을 포함하여 약 $98,783입니다. 비트코인 구매에는 판매 계약에 따른 주식 발행 및 판매 수익금이 사용되었습니다.\n",
      "\n",
      "2024년 12월 8일 기준으로 회사와 그 자회사들은 총 약 423,650 비트코인을 보유하고 있습니다. 이는 수수료와 비용을 포함하여 총 약 $25.6 billion의 구매 가격에 비트코인당 평균 $60,324에 매입한 것입니다.\n",
      "\n",
      "항목 7.01\n",
      "\n",
      "Regulation FD 공시.\n",
      "\n",
      "BTC Yield KPI\n",
      "\n",
      "2024년 10월 1일부터 2024년 12월 8일까지 회사의 BTC Yield는 43.2%였습니다. 2024년 1월 1일부터 2024년 12월 8일까지 회사의 BTC Yield는 68.7%였습니다.\n",
      "\n",
      "BTC Yield는 회사의 비트코인 보유량과 가정된 희석주식수 사이의 비율의 기간별 변화율을 나타내는 주요 성과 지표(\"KPI\")입니다. 가정된 희석주식수는 해당 기간 말 기준 회사의 실제 발행 보통주 총수에 모든 미전환 전환사채의 가정된 전환, 모든 미행사 주식 옵션의 행사, 그리고 모든 미정산 제한주식 유닛 및 성과주식 유닛의 정산으로 인해 발생할 수 있는 모든 추가 주식을 더한 것을 의미합니다. 회사는 BTC Yield를 주주들에게 이익이 된다고 믿는 방식으로 비트코인을 취득하는 전략의 성과를 평가하는 데 도움이 되는 KPI로 사용합니다. 회사는 이 KPI가 투자자들이 회사의 추가 보통주 또는 보통주로 전환 가능한 상품 발행을 통한 비트코인 구매 자금 조달 결정을 이해하는 데 도움이 될 수 있다고 믿습니다.\n",
      "\n",
      "BTC Yield 및 기본 및 가정된 희석주식수\n",
      "\n",
      "     2023-12-31      2024-09-30      2024-12-08  \n",
      "\n",
      "총 비트코인 보유량\n",
      "\n",
      "     189,150        252,220        423,650  \n",
      "\n",
      "발행주식수 (천 주) (1)\n",
      "\n",
      " \n",
      "\n",
      "A종\n",
      "\n",
      "     149,041        182,995        220,007  \n",
      "\n",
      "B종\n",
      "\n",
      "     19,640        19,640        19,640   \n",
      "\n",
      "기본주식수 (2)\n",
      "\n",
      "     168,681        202,635        239,647  \n",
      "\n",
      "2025년 전환사채 @$39.80\n",
      "\n",
      "     16,330        —         —   \n",
      "\n",
      "2027년 전환사채 @$143.25\n",
      "\n",
      "     7,330        7,330        7,330  \n",
      "\n",
      "2028년 전환사채 @$183.19\n",
      "\n",
      "     —         5,513        5,513  \n",
      "\n",
      "2029년 전환사채 @$672.40\n",
      "\n",
      "     —         —         4,462  \n",
      "\n",
      "2030년 전환사채 @$149.77\n",
      "\n",
      "     —         5,342        5,342  \n",
      "\n",
      "2031년 전환사채 @$232.72\n",
      "\n",
      "     —         2,594        2,594  \n",
      "\n",
      "2032년 전환사채 @$204.33\n",
      "\n",
      "     —         3,915        3,915  \n",
      "\n",
      "미행사 옵션\n",
      "\n",
      "     12,936        5,678        4,985  \n",
      "\n",
      "미확정 RSU/PSU\n",
      "\n",
      "     2,359        2,034        1,854   \n",
      "\n",
      "가정된 희석주식수 (3)\n",
      "\n",
      "     207,636        235,042        275,642  \n",
      "\n",
      "BTC Yield % (분기 누적)\n",
      "\n",
      "           43.2%  \n",
      "\n",
      "BTC Yield % (연간 누적)\n",
      "\n",
      "           68.7%  \n",
      "\n",
      "(1)\n",
      "\n",
      "2024년 7월 11일, 회사는 A종 보통주와 B종 보통주의 10대 1 주식 분할을 발표했습니다. 주식 분할은 2024년 8월 1일 영업 종료 시점을 기준일로 하여 A종 보통주와 B종 보통주 보유자들에게 주식 배당의 형태로 이루어졌습니다. 배당은 2024년 8월 7일 거래 종료 후 배분되었으며, 2024년 8월 8일 시장 개장 시 분할 조정된 기준으로 거래가 시작되었습니다. 주식 분할의 결과로, 모든 해당 주식 및 주식 보상 정보는 제시된 모든 기간에 대해 소급 조정되어 주식 분할을 반영하고 있습니다.\n",
      "\n",
      "(2)\n",
      "\n",
      "기본주식수는 제시된 날짜 기준의 실제 A종 보통주와 B종 보통주 발행 주식수를 반영합니다. 이 계산을 위해, 해당 주식의 발행 주식수에는 ATM 주식 공모 프로그램에 따라 판매된 주식 또는 행사된 옵션이나 확정된 제한주식 유닛에 따라 발행 예정이었지만 제시된 날짜 기준으로 발행이 보류 중이었던 주식이 포함된 것으로 간주됩니다.\n",
      "\n",
      "(3)\n",
      "\n",
      "가정된 희석주식수는 각 기간 말 기준 기본주식수의 총계에 모든 미전환 전환사채의 가정된 전환, 모든 미행사 주식 옵션의 행사, 그리고 모든 미정산 제한주식 유닛 및 성과주식 유닛의 정산으로 인해 발생할 수 있는 모든 추가 주식을 더한 것을 의미합니다. 가정된 희석주식수는 자기주식법을 사용하여 계산되지 않으며, (주식 보상의 경우) 확정 조건, 주식 옵션의 행사 가격, 또는 전환사채 상품의 전환 가능성을 제한하는 계약 조건을 고려하지 않습니다.\n",
      "\n",
      "BTC Yield KPI에 대한 중요 정보\n",
      "\n",
      "BTC Yield는 회사의 비트코인 보유량과 가정된 희석주식수 사이의 비율의 기간별 변화율을 나타내는 KPI입니다. 가정된 희석주식수는 각 기간 말 기준 회사의 실제 발행 보통주 총수에 모든 미전환 전환사채의 가정된 전환, 모든 미행사 주식 옵션의 행사, 그리고 모든 미정산 제한주식 유닛 및 성과주식 유닛의 정산으로 인해 발생할 수 있는 모든 추가 주식을 더한 것을 의미합니다. 가정된 희석주식수는 자기주식법을 사용하여 계산되지 않으며, (주식 보상의 경우) 확정 조건, 주식 옵션의 행사 가격, 또는 전환사채 상품의 전환 가능성을 제한하는 계약 조건을 고려하지 않습니다.\n",
      "\n",
      "회사는 BTC Yield를 주주들에게 이익이 된다고 믿는 방식으로 비트코인을 취득하는 전략의 성과를 평가하는 데 도움이 되는 KPI로 사용합니다. 회사는 이 KPI가 투자자들이 회사의 추가 보통주 또는 보통주로 전환 가능한 상품 발행을 통한 비트코인 구매 자금 조달 결정을 이해하는 데 도움이 될 수 있다고 믿습니다. 회사가 이 KPI를 사용할 때, 경영진은 이 지표의 다양한 한계도 고려합니다. 여기에는 부채와 보통주 지분보다 우선순위가 높은 회사 자산에 대한 기타 부채 및 청구권을 고려하지 않는다는 점, 그리고 모든 부채가 재융자되거나 회사의 선순위 전환사채의 경우 각각의 조건에 따라 보통주로 전환될 것이라고 가정한다는 점이 포함됩니다.\n",
      "\n",
      "또한, 이 KPI는 운영 성과 지표나 재무 또는 유동성 지표가 아니며, 그렇게 이해되어서도 안 됩니다. 특히, BTC Yield는 전통적인 금융 맥락에서의 \"수익률\"과 동일하지 않습니다. 이는 회사 주주들이 과거에 달성했거나 미래에 달성할 수 있는 투자 수익률의 척도가 아니며, 회사의 운영이나 비트코인 보유로 인해 발생하는 수입, 비트코인 보유에 대한 투자 수익률, 또는 기타 유사한 사업이나 자산 성과의 재무 지표가 아닙니다.\n",
      "\n",
      "회사의 A종 보통주 거래 가격은 회사가 보유한 비트코인의 양과 실제 또는 잠재적 발행 주식 수 외에도 수많은 요인에 의해 결정되며, 그 결과 회사 주식의 시장 가치는 회사가 보유한 비트코인의 시장 가치에 비해 할인 또는 할증된 가격으로 거래될 수 있습니다. BTC Yield는 회사의 A종 보통주 거래 가격을 나타내거나 예측하지 않습니다.\n",
      "\n",
      "위에서 언급한 바와 같이, 이 KPI는 그 목적이 제한적이며 경영진이 회사가 비트코인 보유와 관련하여 주주들에게 이익이 되는 방식으로 자본을 사용하고 있는지 평가하는 데 도움을 주기 위해 사용됩니다.\n",
      "\n",
      "이 KPI를 계산할 때, 회사는 비트코인 취득에\n",
      "\n",
      "이 기사는 인공지능의 도움을 받아 번역됐습니다. 자세한 내용은 이용약관을 참조하시기 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://kr.investing.com/news/cryptocurrency-news/article-432SI-1296993'\n",
    "p0 = re.compile(pattern=r'\\s+\\r\\n\\s+')\n",
    "p1 = re.compile(pattern=r'\\n+')\n",
    "p2 = re.compile(pattern=r'(읽기|provided|[a-z0-9]@[a-z0-9]|무단전재 및 재배포|이 글의 독자는 인베스팅프로 결제 시 쿠폰 코드|인베스팅닷컴 유저를 위한|지금 인베스팅프로)', flags=re.IGNORECASE)\n",
    "p3 = re.compile(pattern=r'([가-힣])\\.(\\w)')\n",
    "p4 = re.compile(pattern=r'\\.━')\n",
    "p5 = re.compile(pattern=r'\\n{3,}')\n",
    "# 일부 파라미터들을 고정한 investing 함수 생성\n",
    "fixed_investing = partial(investing,\n",
    "                            headers=headers, allow_redirects=allow_redirects, timeout=timeout, max_retry=max_retry,\n",
    "                            p0=p0, p1=p1, p2=p2, p3=p3, p4=p4, p5=p5)\n",
    "\n",
    "res = fixed_investing(url)\n",
    "print(res['news_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
