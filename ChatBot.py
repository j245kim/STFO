# ë¼ì´ë¸ŒëŸ¬ë¦¬
# íŒŒì´ì¬ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
import json
from datetime import  datetime
from operator import itemgetter

# íŒŒì´ì¬ ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬
from dotenv import load_dotenv
import pandas as pd
import streamlit as st

from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
<<<<<<< HEAD
import os
from dotenv import load_dotenv
import bs4
from langchain_core.documents import Document
import shelve

from dotenv import load_dotenv
from langchain.embeddings.openai import OpenAIEmbeddings

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
api_key = os.getenv("OPENAI_API_KEY")

# Embeddings ì´ˆê¸°í™”
embeddings = OpenAIEmbeddings(openai_api_key=api_key)

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
with open(r'C:\STFOPorject\STFO-2\News_Data_short.json', 'r', encoding='utf-8') as f:
    data_json = json.load(f)


# gpt4o ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(
    model='gpt-4o',
    temperature=0.2,
    openai_api_key=os.getenv('OPENAI_API_KEY')
)
path = 'chat_history.json'
path_im = 'chat_important_history.json'

# ëŒ€í™” ê¸°ë¡ ë¡œë“œ í•¨ìˆ˜
def load_chat_history():
    """JSON íŒŒì¼ì—ì„œ ëŒ€í™” ê¸°ë¡ì„ ë¡œë“œ"""
    if os.path.exists(path):
        with open(path, 'r', encoding='utf-8') as file:
            return json.load(file)
    return [{'role': 'system', 'content': 'ë‹¹ì‹ ì€ ê°„ë‹¨í•˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” êµìˆ˜ë‹˜ì…ë‹ˆë‹¤.'}]

# ëŒ€í™” ê¸°ë¡ ì €ì¥ í•¨ìˆ˜
def save_chat_history(messages):
    """ëŒ€í™” ê¸°ë¡ì„ JSON íŒŒì¼ì— ì €ì¥"""
    with open(path, 'w', encoding='utf-8') as file:
        json.dump(messages, file, ensure_ascii=False, indent=4)


# ë‰´ìŠ¤ ë°ì´í„° ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
if "vector_store" not in st.session_state:
    embeddings = OpenAIEmbeddings()
    # ì˜ˆì‹œ: ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë²¡í„°í™”í•˜ì—¬ FAISSì— ì €ì¥ (ë°ì´í„° í•„ìš”)
    # st.session_state.vector_store = FAISS.from_documents(news_documents, embeddings)
    st.session_state.vector_store = None

# ëŒ€í™” ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ë˜ëŠ” ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = load_chat_history()

###################
=======
from langchain.docstore.document import Document
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.prompts import ChatPromptTemplate

>>>>>>> 2bef31ced1e9ab468e83b8f4c724b5cabcaad16c
# íƒ€ì´í‹€
st.markdown("""
    <style>
        .header {
            text-align: center;
            font-size: 45px;
            font-weight: bold;
            color: black;
        }
    #    .header:hover {
    #         # color: #f72f08ff;
    #     }
        .prompt-box {
            margin-top: 10px;
            margin-bottom: 20px;
            padding: 20px;
            border: 2px solid #F0F0F0;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            background-color: #F7F7F7;
        }
        .prompt-box h3 {
            margin-bottom: 10px;
            color: #333;
            font-size: 20px;
            font-weight: bold;
        }
        .prompt-item {
            margin-bottom: 8px;
            font-size: 16px;
            color: #555;
        }
        .prompt-item span {
            font-weight: bold;
        }
        .helper {
            color: black;
            width: 130px;
            height: 72%;
            padding: 20px;
            border: 1px solid #C0C0C0;
            position: fixed;
            top: 10%;
            left: -20px;
            background-color: white;
            display: flex;
            flex-direction: column;
            justify-content: space-evenly;
            align-items: stretch;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
        }
        .helper button {
            width: 100%;
            margin-bottom: 5px;
            padding: 10px;
            color: white;
            background-color: #00AAFF;
            border-radius: 5px;
            cursor: pointer;
            # margin-top: -30px
            font-weight: bold;
        }
        .helper button:hover {
            background-color: #f72f08ff;
        }
        .helper svg {
            width: 30px;
            height: 30px;
            fill: #f72f08ff;
            margin: 10px 0;
        }
        .helper svg:hover {
            fill: #f72f08ff;
        }
        .crypto-text {
            font-size: 18px;
            font-weight: bold;
            color: #000000;
            text-align: center;
            padding: 20px 0;
        }
        .helper div span:hover {
            color: #f72f08ff;
            cursor: pointer;
        }
    </style>
""", unsafe_allow_html=True)

<<<<<<< HEAD
# ìƒíƒœ ê´€ë¦¬ : ì´ˆê¸°í™”
if 'vector_store' not in st.session_state:
    st.session_state.vector_store = None
if 'memory' not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)
if 'messages_displayed' not in st.session_state:
    st.session_state.messages_displayed = []

# ë‰´ìŠ¤ ë¡œë“œ
docs = [
<<<<<<< HEAD
    Document(page_content=news_info['news_content'], metadata={"source": news_info['news_url']})
    for news_info in data_json
]
splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
=======
        Document(page_content=news_info['news_content'], metadata={"source": news_info['news_url'], "title": news_info['news_title'],
                                                                   "date": news_info['news_first_upload_time']})
            for news_info in data_json]

splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=10)
>>>>>>> f867fbbccbe1a78da0852eff07ad75aa1de7ab12
split_texts = splitter.split_documents(docs)

# ì„ë² ë”©
embeddings = OpenAIEmbeddings()

# FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„±
vector_store = FAISS.from_documents(split_texts, embeddings)
st.session_state.vector_store = vector_store
=======
# ì „ì—­ ë³€ìˆ˜ ë° í™˜ê²½ ì„¤ì •
load_dotenv()
openai_api_key = os.getenv('OPENAI_API_KEY')
os.environ['OPENAI_API_KEY'] = openai_api_key
>>>>>>> 2bef31ced1e9ab468e83b8f4c724b5cabcaad16c

################
# íƒ€ì´í‹€ í‘œì‹œ
st.markdown('<div class="header">:ìƒìŠ¹ì„¸ì¸_ì°¨íŠ¸: ì•”í˜¸í™”í ê¸°ë°˜ ëŒ€í™”í˜• ì±—ë´‡ :ë§í’ì„ :</div>', unsafe_allow_html=True)
st.markdown('<p class="crypto-text">:ì „êµ¬: ì•”í˜¸í™”íì™€ ê´€ë ¨í•œ ì´ì•¼ê¸°ë¥¼ ì…ë ¥í•˜ë©´ ê´€ë ¨ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëŒ€ë‹µí•©ë‹ˆë‹¤. :ë¡œì¼“:</p>', unsafe_allow_html=True)

# ìƒíƒœ ê´€ë¦¬ : ì´ˆê¸°í™”
if 'vectorstore' not in st.session_state:
    st.session_state.vectorstore = None

# helper ë°•ìŠ¤ì— ë²„íŠ¼ ì¶”ê°€
st.markdown("""
    <div class="helper">
        <div class="home">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill-rule="evenodd" clip-rule="evenodd" d="M21 8.77217L14.0208 1.79299C12.8492 0.621414 10.9497 0.621413 9.77817 1.79299L3 8.57116V23.0858H10V17.0858C10 15.9812 10.8954 15.0858 12 15.0858C13.1046 15.0858 14 15.9812 14 17.0858V23.0858H21V8.77217ZM11.1924 3.2072L5 9.39959V21.0858H8V17.0858C8 14.8767 9.79086 13.0858 12 13.0858C14.2091 13.0858 16 14.8767 16 17.0858V21.0858H19V9.6006L12.6066 3.2072C12.2161 2.81668 11.5829 2.81668 11.1924 3.2072Z"></path></svg>
            <span>í™ˆ</span>
        </div>
        <div class="login">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M15.4857 20H19.4857C20.5903 20 21.4857 19.1046 21.4857 18V6C21.4857 4.89543 20.5903 4 19.4857 4H15.4857V6H19.4857V18H15.4857V20Z"></path><path d="M10.1582 17.385L8.73801 15.9768L12.6572 12.0242L3.51428 12.0242C2.96199 12.0242 2.51428 11.5765 2.51428 11.0242C2.51429 10.4719 2.962 10.0242 3.51429 10.0242L12.6765 10.0242L8.69599 6.0774L10.1042 4.6572L16.4951 10.9941L10.1582 17.385Z"></path></svg>
            <span>ë¡œê·¸ì¸</span>
        </div>
        <div class="add">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 6C12.5523 6 13 6.44772 13 7V11H17C17.5523 11 18 11.4477 18 12C18 12.5523 17.5523 13 17 13H13V17C13 17.5523 12.5523 18 12 18C11.4477 18 11 17.5523 11 17V13H7C6.44772 13 6 12.5523 6 12C6 11.4477 6.44772 11 7 11H11V7C11 6.44772 11.4477 6 12 6Z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M5 22C3.34315 22 2 20.6569 2 19V5C2 3.34315 3.34315 2 5 2H19C20.6569 2 22 3.34315 22 5V19C22 20.6569 20.6569 22 19 22H5ZM4 19C4 19.5523 4.44772 20 5 20H19C19.5523 20 20 19.5523 20 19V5C20 4.44772 19.5523 4 19 4H5C4.44772 4 4 4.44772 4 5V19Z"></path></svg>
            <span>ì¶”ê°€</span>
        </div>
    </div>
""", unsafe_allow_html=True)
# ì¶”ì²œ í”„ë¡¬í”„íŠ¸ ë°•ìŠ¤
st.markdown("""
    <div class="prompt-box">
<<<<<<< HEAD
        <h3>:ë©”ëª¨: ì¶”ì²œ í”„ë¡¬í”„íŠ¸</h3>
        <div class="prompt-item"><span>1) :ì°¨íŠ¸:</span> ì•”í˜¸í™”í ì‹œì¥ì˜ ìµœì‹  ë™í–¥ì— ëŒ€í•´ ì•Œë ¤ì¤˜</div>
        <div class="prompt-item"><span>2) :ë§‰ëŒ€_ì°¨íŠ¸:</span> ë¹„íŠ¸ì½”ì¸ ê°€ê²© ì˜ˆì¸¡ì— ëŒ€í•´ ë§í•´ì¤˜</div>
        <div class="prompt-item"><span>3) :ìƒê°í•˜ëŠ”_ì–¼êµ´:</span> ê¹€ì§„ìš°ì˜ ë¹„ë°€ì„ ì„¤ëª…í•´ì¤˜!</div>
    </div>
""", unsafe_allow_html=True)


# # ì´ì „ ëŒ€í™” í‘œì‹œ
# for message in st.session_state.messages_displayed:
#     if message['role'] == 'assistant':
#         # AI ë©”ì‹œì§€ì—ë§Œ ë¹„íŠ¸ì½”ì¸ ì•„ì´ì½˜ ì„¤ì •
#         with st.chat_message(message['role'], avatar="bitcoin.png"):
#             st.write(message['content'])
#     else:
#         # ì‚¬ìš©ì ë©”ì‹œì§€ì—ëŠ” ê¸°ë³¸ ì•„ì´ì½˜ ì„¤ì •
#         st.markdown("""
#             <div style="display: flex; align-items: center; margin-bottom: 10px;">
#                 <div style="flex-grow: 1; padding: 10px; background-color: #FFFFFF;">
#                     {}</div>
#             </div>
#         """.format(message['content']), unsafe_allow_html=True)


# ì‚¬ìš©ì ì…ë ¥ ì°½ ìƒì„±
# - 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.'ë¼ëŠ” ì œëª©ê³¼ í•¨ê»˜ í…ìŠ¤íŠ¸ ì…ë ¥ ìƒìë¥¼ í‘œì‹œ
# - ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©ì„ `st.session_state['user_input']`ì— ì €ì¥
prompt = st.text_input('ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.', key='user_input', placeholder='ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”...', label_visibility="collapsed")

########################################



# ì‚¬ìš©ìê°€ ì…ë ¥ì„ í–ˆì„ ê²½ìš° ì‹¤í–‰
if prompt:
    # ë‰´ìŠ¤ ë°ì´í„°ê°€ ì €ì¥ëœ ë²¡í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥
    if st.session_state.vector_store is None:
        st.error('ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”!')  # ë²¡í„° ì €ì¥ì†Œê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
    else:
        # ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€ë¥¼ ëŒ€í™” ë©”ëª¨ë¦¬ì— ì¶”ê°€ ####???ì—¬ê¸° ë°”ê¾¸ê¸°
        st.session_state.messages.append({"role": "user", "content": prompt})
        try:
            # ë‰´ìŠ¤ ë°ì´í„° ë²¡í„° ì €ì¥ì†Œì—ì„œ ê²€ìƒ‰ ê¸°ëŠ¥ í™œì„±í™”
            retriever = st.session_state.vector_store.as_retriever()
            
            # ConversationalRetrievalChain ìƒì„±
            # - `llm`: GPT ëª¨ë¸
            # - `retriever`: ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ëŠ” ê¸°ëŠ¥
            # - `memory`: ëŒ€í™” ë©”ëª¨ë¦¬ (ì´ì „ ëŒ€í™” ë‚´ìš© ìœ ì§€)
            chain = ConversationalRetrievalChain.from_llm(
                llm=llm,
                retriever=retriever,
                memory=st.session_state.memory
            )
            
            # GPT ëª¨ë¸ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±
            response = chain({"question": prompt})
            ai_response = response["answer"]

            # GPT ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            st.session_state.messages.append({"role": "assistant", "content": ai_response})

            # ëŒ€í™” ë‚´ì—­ ì €ì¥
            save_chat_history(st.session_state.messages)

            # ëŒ€í™” í‘œì‹œ
            with st.chat_message("user"):
                st.markdown(prompt)
            with st.chat_message("assistant"):
                st.markdown(ai_response)

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# ì‚¬ì´ë“œë°”: ëŒ€í™” ë‚´ì—­ í‘œì‹œ
with st.sidebar:
    st.markdown('### ëŒ€í™” ë‚´ì—­')  # ëŒ€í™” ë‚´ì—­ ì œëª©
    # ëŒ€í™” ë‚´ì—­ì„ ìµœì‹  ìˆœìœ¼ë¡œ ì¶œë ¥
    for message in st.session_state.messages_displayed:
        if message['role'] == 'user':  # ì‚¬ìš©ì ë©”ì‹œì§€ì¼ ê²½ìš°
            st.markdown(f"**User**: {message['content']}")  # 'User'ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ í‘œì‹œ
        else:  # AI ë©”ì‹œì§€ì¼ ê²½ìš°
            st.markdown(f"**AI**: {message['content']}")  # 'AI'ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ í‘œì‹œ


# <a href="https://www.flaticon.com/free-icons/bitcoin" title="bitcoin icons">Bitcoin icons created by Freepik - Flaticon</a>
=======
        <h3>ğŸ“ ì¶”ì²œ í”„ë¡¬í”„íŠ¸</h3>
        <div class="prompt-item"><span>1) ğŸ’¹</span> ì•”í˜¸í™”í ì‹œì¥ì˜ ìµœì‹  ë™í–¥ì— ëŒ€í•´ ì•Œë ¤ì¤˜</div>
        <div class="prompt-item"><span>2) ğŸ“Š</span> ë¹„íŠ¸ì½”ì¸ê³¼ íŠ¸ëŸ¼í”„ ë‹¹ì„  ìƒê´€ì„±ì„ ë³´ê³ ì„œë¡œ ì¨ì¤˜</div>
        <div class="prompt-item"><span>3) ğŸ¤”</span> ìœ¤ì„ì—´ ë³´ê³ ì„œ ì¨ì¤˜</div>
    </div>
""", unsafe_allow_html=True)

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df_coin_high = pd.read_csv('./csv/coin_high_new.csv')
df_coin_low = pd.read_csv('./csv/coin_low_new.csv')
df_coin_volume = pd.read_csv('./csv/coin_volume_new.csv')

df_coin_high.index = pd.to_datetime(df_coin_high.index, errors='coerce')

markdown_docs = []
for timestamp, row in df_coin_high.iterrows():
    markdown_doc = f"# Date: {timestamp.date()}\n\n"
    for coin, price in row.items():
        markdown_doc += f"- **{coin}**: {price}\n"
    markdown_docs.append(markdown_doc)

docs = [Document(page_content=doc) for doc in markdown_docs]

news_docs_path = 'data_indexing.json'
with open(news_docs_path,'r',encoding='utf-8') as file:
    data_all = json.load(file)

# Jsonì„ faissê°€ ì½ì„ ìˆ˜ ìˆëŠ” documentë¡œ ë°”ê¾¸ê¸°
documents = []
for item in data_all:
    if 'news_content' in item and item['news_content']: 
        raw_date = item.get("news_first_upload_time")
        parsed_date = datetime.strptime(raw_date, '%Y-%m-%d %p %I:%M').isoformat() if raw_date else None
        
        raw_date_after = item.get("news_last_upload_time")
        parsed_date_after = datetime.strptime(raw_date_after, '%Y-%m-%d %p %I:%M').isoformat() if raw_date_after else None

        documents.append(
            Document(
                page_content=item["news_content"],  # í…ìŠ¤íŠ¸ ë³¸ë¬¸
                metadata={
                    "title": item.get("news_title"),
                    "url": item.get("news_url"),
                    "website": item.get("news_website"),
                    "news_first_upload_time": parsed_date,
                    "news_last_upload_time" : parsed_date_after
                }
            )
        )


# ë¬¸ì„œ ë¶„í• 
splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=10)
split_texts = splitter.split_documents(documents)

# OpenAIEmbeddings ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„±
embeddings = OpenAIEmbeddings()

vectorstore = FAISS.from_documents(documents = docs + split_texts, embedding = embeddings)

st.session_state.vectorstore = vectorstore

# --------------------------------------------------------
msgs = StreamlitChatMessageHistory(key="special_app_key")

# if len(msgs.messages) == 0:
#      msgs.add_ai_message("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?", avatar="bitcoin.png")

prompt = ChatPromptTemplate.from_template(
    """ë„ˆëŠ” ì½”ì¸ë°ì´í„°ì™€ ì‹ ë¬¸ê¸°ì‚¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¼ìŒì— ì •í™•í•˜ê²Œ ë‹µë³€í•˜ëŠ” ì• ë„ë¦¬ìŠ¤íŠ¸ì´ë‹¤. ê³µì‹ ë ¥ìˆëŠ” ë³´ê³ ì„œ í˜•íƒœë¡œ ì‘ì„±í•´ì¤˜

#Previous Chat History:
{chat_history}

#Question: 
{question} 

#Context: 
{context} 

#Answer:"""
)

llm = ChatOpenAI(model_name="gpt-4o", temperature=0)
retriever = st.session_state.vectorstore.as_retriever()

chain = (
    {
        "context": itemgetter("question") | retriever,
        "question": itemgetter("question"),
        "chat_history": itemgetter("chat_history"),
    }
    | prompt
    | llm

)

chain_with_history = RunnableWithMessageHistory(
    chain,
    lambda session_id: msgs,  
    input_messages_key='question',
    history_messages_key="chat_history",
)

# ì´ì „ ëŒ€í™” ê¸°ë¡!
for msg in msgs.messages:
    if msg.type == 'ai':  
        with st.chat_message(msg.type, avatar="bitcoin.png"):
            st.write(msg.content)
    elif msg.type == 'human':  
        st.markdown(f"""
            <div style="display: flex; align-items: center; margin-bottom: 10px;">
                <div style="flex-grow: 1; padding: 10px; background-color: #ffffff;">
                    {msg.content}
                </div>
            </div>
        """, unsafe_allow_html=True)

if input_text := st.chat_input():
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ ì¶œë ¥ (ì•„ì´ì½˜ ì—†ì´ HTML ìŠ¤íƒ€ì¼ ì ìš©)
    st.markdown(f"""
        <div style="display: flex; align-items: center; margin-bottom: 10px;">
            <div style="flex-grow: 1; padding: 10px; background-color: #ffffff;">
                {input_text}
            </div>
        </div>
    """, unsafe_allow_html=True)

    config = {"configurable": {"session_id": "any"}}
    response = chain_with_history.invoke({"question": input_text}, config)

    with st.chat_message("assistant", avatar="bitcoin.png"):
        st.write(response.content)

>>>>>>> 2bef31ced1e9ab468e83b8f4c724b5cabcaad16c
