{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import streamlit as st\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# JSON 파일 경로\n",
    "path = 'chat_history.json'\n",
    "\n",
    "# 대화 기록 로드 함수\n",
    "def load_chat_history():\n",
    "    \"\"\"JSON 파일에서 대화 기록을 로드\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            return json.load(file)\n",
    "    return [{'role': 'system', 'content': '당신은 간단하고 논리적으로 답변하는 교수님입니다.'}]\n",
    "\n",
    "# 대화 기록 저장 함수\n",
    "def save_chat_history(messages):\n",
    "    \"\"\"대화 기록을 JSON 파일에 저장\"\"\"\n",
    "    with open(path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(messages, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Streamlit 앱 설정\n",
    "st.title(\"뉴스 검색 및 대화형 챗봇\")\n",
    "\n",
    "# GPT 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2, openai_api_key=\"YOUR_API_KEY\")\n",
    "\n",
    "# 뉴스 데이터 벡터 저장소 초기화\n",
    "if \"vector_store\" not in st.session_state:\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # 예시: 뉴스 데이터를 벡터화하여 FAISS에 저장 (데이터 필요)\n",
    "    # st.session_state.vector_store = FAISS.from_documents(news_documents, embeddings)\n",
    "    st.session_state.vector_store = None\n",
    "\n",
    "# 대화 메모리 초기화\n",
    "if \"memory\" not in st.session_state:\n",
    "    st.session_state.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# 대화 기록 불러오기 또는 초기화\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = load_chat_history()\n",
    "\n",
    "# 사용자 입력\n",
    "prompt = st.text_input(\"메시지를 입력하세요.\", key=\"user_input\", placeholder=\"메시지를 입력해주세요...\", label_visibility=\"collapsed\")\n",
    "\n",
    "# 사용자 입력 처리\n",
    "if prompt:\n",
    "    if st.session_state.vector_store is None:\n",
    "        # 벡터 저장소가 없으면 에러 메시지 출력\n",
    "        st.error(\"뉴스 데이터를 불러오지 못했습니다. 다시 시도해주세요.\")\n",
    "    else:\n",
    "        # 사용자 메시지를 대화 기록에 추가\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "        # 뉴스 데이터 벡터 저장소에서 검색 기능 활성화\n",
    "        retriever = st.session_state.vector_store.as_retriever()\n",
    "        chain = ConversationalRetrievalChain.from_llm(\n",
    "            llm=llm,\n",
    "            retriever=retriever,\n",
    "            memory=st.session_state.memory\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            # GPT 모델로 질문에 대한 응답 생성\n",
    "            response = chain({\"question\": prompt})\n",
    "            ai_response = response[\"answer\"]\n",
    "\n",
    "            # GPT 응답을 대화 기록에 추가\n",
    "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "\n",
    "            # 대화 내역 저장\n",
    "            save_chat_history(st.session_state.messages)\n",
    "\n",
    "            # 대화 표시\n",
    "            with st.chat_message(\"user\"):\n",
    "                st.markdown(prompt)\n",
    "            with st.chat_message(\"assistant\"):\n",
    "                st.markdown(ai_response)\n",
    "\n",
    "        except Exception as e:\n",
    "            st.error(f\"오류가 발생했습니다: {e}\")\n",
    "\n",
    "# 이전 대화 내역 표시\n",
    "st.markdown(\"### 대화 내역\")\n",
    "for message in st.session_state.messages:\n",
    "    if message[\"role\"] == \"user\":\n",
    "        st.markdown(f\"**User**: {message['content']}\")\n",
    "    elif message[\"role\"] == \"assistant\":\n",
    "        st.markdown(f\"**Assistant**: {message['content']}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
